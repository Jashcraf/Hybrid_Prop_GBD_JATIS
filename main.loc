\ChangesListline {deleted}{Deleted}{, and polarization}{1}
\ChangesListline {added}{Added}{}{1}
\ChangesListline {deleted}{Deleted}{and open-source}{1}
\ChangesListline {added}{Added}{We develop a formal algorithm for the transfer-matrix method of GBD, and evaluate it against analytical results and traditional physical optics model to assess the suitability of GBD for high-contrast imaging simulations.}{1}
\ChangesListline {deleted}{Deleted}{speckle}{1}
\ChangesListline {replaced}{Replaced}{4 $\times 10^{-11}$}{1}
\ChangesListline {deleted}{Deleted}{, polarization,}{1}
\ChangesListline {added}{Added}{We developed this algorithm in an open-source software package and outlined a path for its continued development to increase the fidelity and flexibility of diffraction simulations using GBD.}{1}
\ChangesListline {deleted}{Deleted}{of the telescope}{2}
\ChangesListline {replaced}{Replaced}{An example of this is the linear and shift-invariant assumption imposed on diffraction models of astronomical observatories. Ray aberrations (e.g. coma, astigmatism) have a field dependence, and consequently change across an observatory's field of view. However, diffraction integrals assume shift-invariance. This means that the aberrations do not change across the field of view and a separate ray trace model must be used to capture this effect.}{2}
\ChangesListline {added}{Added}{In the prior example, to capture the influence of optical aberrations a new ray trace must be performed and the optical path difference of the rays must be translated to a diffraction model for each point of interest in the field of view.}{2}
\ChangesListline {replaced}{Replaced}{Similarly, diffraction integrals are incapable of determining the effects of optical polarization. For example,}{2}
\ChangesListline {added}{Added}{Modern space telescopes also require integrated models to accurately predict the instrument behavior. For example, }{3}
\ChangesListline {deleted}{Deleted}{generally}{3}
\ChangesListline {replaced}{Replaced}{effects}{3}
\ChangesListline {replaced}{Replaced}{orders of magnitude dimmer than }{3}
\ChangesListline {replaced}{Replaced}{ meter}{3}
\ChangesListline {added}{Added}{linearized }{4}
\ChangesListline {replaced}{Replaced}{integrate }{4}
\ChangesListline {added}{Added}{Open-source Packages that currently support Fresnel diffraction include:}{4}
\ChangesListline {deleted}{Deleted}{and}{4}
\ChangesListline {added}{Added}{AOTools\cite {Townson:19}, and prysm \cite {Dube2022,Dube2019}}{4}
\ChangesListline {deleted}{Deleted}{The Fast Linearized Coronagraph Optimizer (FALCO) package\cite {Riggs18} uses the same propagation physics to aid the design of these instruments by optimizing the commands sent to deformable mirrors to correct for the near-field diffraction effects that could limit the Roman Space Telescope (Roman) Coronagraph Instrument's sensitivity. }{5}
\ChangesListline {replaced}{Replaced}{, or PIAA }{5}
\ChangesListline {added}{Added}{To continue the development of integrated optical models, exploring the possibilities and limitations of new propagation physics is desirable.}{5}
\ChangesListline {added}{Added}{An example of the typical integrated modeling pipeline for astronomical observatories outfitted with coronagraphs is shown in Figure \ref {fig:modeling_flow}. The observatory is typically designed and modeled in ray trace software (e.g. CODE V, Zemax OpticStudio) to accurately model the wavefront in the observatory's exit pupil. Upon finalizing the design, the complex-valued exit pupil is decomposed into a functional representation (e.g. a set of polynomial coefficients, such as the Zernikes\cite {krist_numerical_2015}) and passed to the entrance pupil of a coronagraph model constructed in an open-source, Fourier-based physical optics propagator (e.g. POPPY, PROPER, HCIPy). The front-end model computes the complex field distribution at the coronagraph mask, and then propagates the field past the mask to the image plane. The flux field is taken by a model of the detector (e.g. EMCCD Detect\cite {Nemati2023}, Pyxel\cite {Pyxel}) to create a simulated raw science image that can be post-processed (e.g. PyKLIP\cite {pyklip}, NMF imaging\cite {nmfimaging}).}{6}
\ChangesListline {added}{Added}{Traditionally, GBD operates using the complex ray tracing algorithm described in the works by Greynolds\cite {Greynolds86} and Harvey et al\cite {Harvey15}}{6}
\ChangesListline {replaced}{Replaced}{An alternative approach called the transfer matrix algorithm was recently developed to improve GBD's viability for precision diffraction simulation by Worku and Gross}{7}
\ChangesListline {added}{Added}{To formally evaluate GBD as a modeling tool for astronomical instrumentation, a complete algorithm for its implementation is derived here.}{7}
\ChangesListline {added}{Added}{The operating principle of GBD is to decompose the field in the entrance pupil of an optical system (Figure \ref {fig:gbd_essentials}a) into a finite set of Gaussian beams (Figure \ref {fig:gbd_essentials}b). Their coherent sum (Figure \ref {fig:gbd_essentials}c-d) approximates the initial field decomposition.}{7}
\ChangesListline {added}{Added}{Illustration of the operating principle of GBD in one dimension. The aperture function for traditional imaging systems is shown in (a) as a top-hat function of uniform amplitude. The decomposition of this function into a discrete set of Gaussian beams is shown in (b), which shows nine evenly-spaced Gaussian profiles before their coherent summation, which is shown in (c). The coherent sum (black) of these nine beamlets shows that the beamlets are incapable of perfectly reconstructing the original aperture function (dashed red), specifically the sharp edge and uniform amplitude. More beamlets are needed for a more accurate reconstruction, which is shown in (d) for 199 beamlets. The amplitude ripple has virtually vanished, and the field near the aperture edges is almost entirely recovered.}{8}
\ChangesListline {added}{Added}{Under-sampling the field in the entrance pupil leads to artifacts in the decomposition. A characteristic amplitude ripple based on the period of the beamlet decomposition remains in the field. Due to the soft edges of the Gaussian beams, they cannot completely reconstruct the field of a sharp aperture edge. Using a larger number of smaller beamlets decreases the beamlet distribution period and increases the slope of the Gaussian beams, allowing for the mitigation of both of these effects (shown in Figure \ref {fig:gbd_essentials}d).}{8}
\ChangesListline {added}{Added}{Upon decomposing the initial wavefront into a sufficient set of Gaussian beams, we can use their analytical linear propagation laws\cite {Siegman_1986} (described in Section \ref {sec:methods} of this manuscript) to compute the coherent field at any arbitrary plane in the optical system.}{8}
\ChangesListline {replaced}{Replaced}{stellar}{8}
\ChangesListline {added}{Added}{but may not be for next-generation observatories whose large apertures may necessitate relatively fast telescope optics}{8}
\ChangesListline {deleted}{Deleted}{Observatories are designed and modeled in ray trace software (e.g. CODE V, Zemax OpticStudio) to accurately model the wavefront in the exit pupil. Upon finalizing the design, the complex-valued exit pupil is decomposed into a functional representation (e.g. a set of polynomial coefficients, such as the Zernikes\cite {krist_numerical_2015}) and sent to an open-source Fourier-based physical optics propagator (e.g. POPPY, PROPER, HCIPy) to generate the complex field at the image plane. The flux field is taken by a model of the detector (e.g. EMCCD Detect, Pyxel\cite {Pyxel}) to create a simulated raw science image that can be post-processed (e.g. PyKLIP\cite {pyklip}, NMF imaging\cite {nmfimaging}).}{9}
\ChangesListline {deleted}{Deleted}{aims to}{9}
\ChangesListline {added}{Added}{s}{9}
\ChangesListline {replaced}{Replaced}{observatory}{9}
\ChangesListline {replaced}{Replaced}{coherent}{9}
\ChangesListline {deleted}{Deleted}{a generally astigmatic}{9}
\ChangesListline {added}{Added}{s}{9}
\ChangesListline {added}{Added}{instead of the entire observatory}{9}
\ChangesListline {replaced}{Replaced}{This locality}{9}
\ChangesListline {added}{Added}{simulation of the}{9}
\ChangesListline {replaced}{Replaced}{.}{9}
\ChangesListline {deleted}{Deleted}{where $h_{1,2}$ are the coordinates of the parabasal rays on the plane transverse to propagation with an origin defined by the central ray and $\theta _{1,2}$ are the angles between the parabasal rays and the central ray.}{9}
\ChangesListline {replaced}{Replaced}{translating}{9}
\ChangesListline {replaced}{Replaced}{to a physical optics propagator}{9}
\ChangesListline {added}{Added}{Another GBD approach, }{10}
\ChangesListline {deleted}{Deleted}{Gaussian}{10}
\ChangesListline {added}{Added}{Our goal is to publicize the transfer matrix method by developing an algorithm for its implementation, and then use it to characterize GBD's suitability for high-contrast imaging simulation. Our work can then be used as a platform with which to study the suitability of Worku and Gross' modified GBD by future investigators.}{10}
\ChangesListline {added}{Added}{Structure in the field where the initial decomposition occurs (typically, the entrance pupil) can be well-represented by Gaussian beams as long as the structure of interest is larger than the beamlets used in decomposition. Diffraction from structure in interemediate planes (between the pupil and focal planes) is challenging to represent if the beamlets diverge considerably. However, secondary beamlets can be traced from these intermediate structures to aid in the accuracy of the simulation\cite {Greynolds14}. At the focal plane of a diffraction-limited system, the rays are highly concentrated while the diffracted field spreads out considerably (e.g. the Airy disk). Because of GBD's reliance on ray tracing, it cannot represent diffraction from structure in the focal plane well without re-decomposing the field \cite {modeling_coherence_fred}.}{11}
\ChangesListline {added}{Added}{the case of}{11}
\ChangesListline {deleted}{Deleted}{consequently}{11}
\ChangesListline {added}{Added}{(shown in Figure \ref {fig:hybridpropdiagram})}{11}
\ChangesListline {replaced}{Replaced}{model}{12}
\ChangesListline {added}{Added}{Our GBD module was built in the Poke\cite {Ashcraft_poke_2022} Python package currently available on Github. Poke was originally developed to be a polarization ray tracing module to study the influence of polarization aberrations on astronomical coronagraphs\cite {anche_inprep}, but we expanded it to include GBD. Poke operates by using ray tracer API's to trace a raybundle through every surface in the optical system. The relevant ray data is stored in a Rayfront Python object and can be loaded into a Python environment and interacted with independent of the raytracer that generated the data. The Rayfronts can also be compiled into binary file types using the msgpack\cite {msgpack} package and distributed to any interested investigator, effectively open-sourcing the physical optics calculations done on ray data.}{13}
\ChangesListline {added}{Added}{Illustration of Poke's use as an interface to open-source ray-based physical optics. Poke only requires an interface between a ray tracing engine (orange, left) to generate and save a Rayfront object, which includes all ray data necessary for the GBD calculation. Currently, Poke supports sequential systems in CODE V and Zemax, but we are working on adding support for open-source packages that have ray tracers, like ray-optics\cite {rayoptics}. The GBD field that Poke computes can then be sent to any open-source diffraction modeling package (yellow, right) to complete the hybrid propagation model.}{13}
\ChangesListline {added}{Added}{In this study we conduct ray traces in Zemax, which are then saved as a Poke Rayfront object. Poke performs the GBD simulations using the saved ray data to generate the field at the focal plane of the telescope. This data is exported to a coronagraph model built using HCIPy.}{13}
\ChangesListline {replaced}{Replaced}{Preliminary Mathematical Methods}{14}
\ChangesListline {deleted}{Deleted}{To assess the viability of GBD for high-contrast imaging simulation we compare the PSF produced by GBD to other diffraction methods that represent the state of the art. Traditional GBD is known to not reconstruct high spatial frequency information because of its inability to recreate sharp edges exactly and residual ripple that is left from the beamlet distribution\cite {Harvey15}, but this has not been quantitatively studied in the literature.}{14}
\ChangesListline {added}{Added}{necessary mathematical tools that we need to formulate our GBD algorithm. This includes the}{14}
\ChangesListline {replaced}{Replaced}{how to use}{14}
\ChangesListline {added}{Added}{to arbitrarily compute the parameters necessary}{14}
\ChangesListline {replaced}{Replaced}{Propagation of a single Gaussian beam}{14}
\ChangesListline {deleted}{Deleted}{To propagate an arbitrary optical beam the field must be decomposed into a finite sum of Gaussian beamlets which are then independently propagated.}{14}
\ChangesListline {added}{Added}{The equation for }{14}
\ChangesListline {replaced}{Replaced}{parameterized}{15}
\ChangesListline {added}{Added}{\cite {Siegman_1986}}{15}
\ChangesListline {added}{Added}{We can then express the propagated Gaussian beam with equation \ref {eq:gaussian_prop}}{16}
\ChangesListline {added}{Added}{Where $\mathbf {r}$ is the radial coordinate in the plane transverse to propagation.}{16}
\ChangesListline {replaced}{Replaced}{an arbitrary }{18}
\ChangesListline {added}{Added}{of the differential ray tracing technique in poke}{19}
\ChangesListline {replaced}{Replaced}{a user-specified ray tracer (e.g. Zemax OpticStudio)}{19}
\ChangesListline {replaced}{Replaced}{The ray coordinates of interest are on the source plane (where the field decomposition is done, e.g. the entrance pupil) and the detector plane (where the propagated field is evaluated, eg. the location of a camera sensor). A local coordinate system is configured on both planes, and the ray positions and directions are computed on these planes}{19}
\ChangesListline {added}{Added}{An element of the ray transfer matrix can be computed by determining the ratio of the differential parameters from the data on the detector plane to the source plane.}{19}
\ChangesListline {replaced}{Replaced}{$A_{y,y}$}{19}
\ChangesListline {replaced}{Replaced}{$y$}{19}
\ChangesListline {added}{Added}{difference in}{19}
\ChangesListline {replaced}{Replaced}{$y$}{19}
\ChangesListline {replaced}{Replaced}{central and differential rays determine the derivative}{19}
\ChangesListline {added}{Added}{(see ABCD matrix in equation \ref {eq:totalabcdmatrix})}{20}
\ChangesListline {added}{Added}{two in position ($\delta x$,$\delta y$) and two in slope ($\delta l$, $\delta m$)}{20}
\ChangesListline {added}{Added}{which are traced in addition to}{21}
\ChangesListline {added}{Added}{central}{21}
\ChangesListline {replaced}{Replaced}{.}{21}
\ChangesListline {added}{Added}{An example of propagating a ray from the source plane to the detector plane is shown in equation \ref {eq:diffmat}. Here the subscript $S$ refers to the coordinate on the source plane, and the subscript $D$ refers to the coordinate on the detector plane.}{21}
\ChangesListline {replaced}{Replaced}{using positive-valued differentials}{21}
\ChangesListline {replaced}{Replaced}{to propagate}{22}
\ChangesListline {deleted}{Deleted}{The same rays can be traced, but by virtue of a different implementation, we have more possibilities for development through the general Collins' integral\cite {Worku19,Collins:70}.}{22}
\ChangesListline {deleted}{Deleted}{Using this matrix, any open-source diffraction model can be linked to a ray trace model of an observatory.}{22}
\ChangesListline {replaced}{Replaced}{The final variable to constrain in GBD is how to appropriately decompose the field in the entrance pupil into a finite set of Gaussian beams. This problem is illustrated in 1D earlier in figure \ref {fig:gbd_essentials}, but the actual decomposition is a 2D problem.}{22}
\ChangesListline {replaced}{Replaced}{Gaussian mode}{22}
\ChangesListline {added}{Added}{'}{23}
\ChangesListline {deleted}{Deleted}{e}{23}
\ChangesListline {added}{Added}{However, because the implementation is not public we must derive the full algorithm using the concepts described in section \ref {sec:methods}. The basic concept of propagating a single beamlet through an arbitrary optical system is illustrated in figure \ref {fig:gaussian_prop_diagram}. A Gaussian beam is placed at some position $r_{S}$ in the source plane where the initial decomposition occurs. The central ray (shown in black on figure \ref {fig:gaussian_prop_diagram}) that emanates from the peak of this Gaussian beam is traced to the detector plane using a ray tracing engine. The data of the central ray at the source plane $(\mathbf {r}_{ray,S}$,$\mathbf {k}_{ray,S})$ and detector plane $(\mathbf {r}_{ray,D}$,$\mathbf {k}_{ray,D})$ (shown in figure \ref {fig:algo1}) are used to propagate the ray to the "transversal plane", which is normal to the central ray and intersects the detector pixel where we are evaluating the field (shown in yellow on figure \ref {fig:gaussian_prop_diagram}). The differential rays are also traced to the transversal plane in order to compute the ABCD matrices that describe the transformation of the Gaussian beam through an arbitrary ray path, and compute the final field incident on the detector pixel.}{24}
\ChangesListline {replaced}{Replaced}{mathematical algorithm}{25}
\ChangesListline {added}{Added}{We refer to several vectors in the algorithm below that are referred to using the convention $\mathbf {x}_{y,Z}$. $\mathbf {x}$ is data type of the vector, typically $\mathbf {r}$ if a position or $\mathbf {k}$ if a direction. $y$ is what item the vector belongs to, "cen" means it belongs to the central ray, "+x" means it belongs to the +x differential ray, "pix" means a pixel on the detector plane. $Z$ refers to the coordinate system of the vector, $D$ for "detector", or $T$ for "transversal". The relevant parameters used in the propagation algorithm are shown in figure \ref {fig:algo1}, and are referenced throughout the procedure below.}{25}
\ChangesListline {added}{Added}{A GBD simulation begins by running a ray trace though an optical system in the user's preferred design code. GBD needs only compute the ray data at the plane where the decomposition occurred (the source plane) and the plane where we choose to observe the field (the detector plane). This is shown for the simple case of a lens with the detector positioned far from focus on figure \ref {fig:algo1}. The source plane (leftmost dashed line) is where the rays used for GBD are started. The detector plane (rightmost dashed line) intersects the ray defined by $\mathbf {k}_{ray,D}$ and includes the pixel that we are evaluating the field at, positioned at coordinate $\mathbf {r}_{pixel,D}$}{26}
\ChangesListline {added}{Added}{Illustration of relevant ray parameters necessary to propagate the ray data to the transversal plane, where we evaluate the Gaussian field that intersects with a detector pixel. A ray that defines a Gaussian beam is placed on the source plane (leftmost vertical dashed line) with some direction ($\mathbf {k}_{ray,S}$) and position ($\mathbf {r}_{ray,S}$) and propagated though the system. At the detector plane (rightmost vertical dashed line), the ray's direction and positions ($\mathbf {k}_{ray,D}$ and $\mathbf {r}_{ray,D}$ respectively) have been transformed by the optical system. To propagate the rays to the transversal plane (tilted dashed line) that intersects the pixel at $\mathbf {r}_{pixel,D}$ where the field evaluation occurs, it must be moved a distance $\Delta _{ray}$ along the ray path in detector space.}{26}
\ChangesListline {added}{Added}{in the coordinates of the detector plane}{28}
\ChangesListline {added}{Added}{(equation \ref {eq:gaussian_prop})}{33}
\ChangesListline {added}{Added}{coupled to a vortex coronagraph}{35}
\ChangesListline {added}{Added}{and is illustrated in figure \ref {fig:telescope_model}}{35}
\ChangesListline {deleted}{Deleted}{-}{35}
\ChangesListline {added}{Added}{Illustration of the hybrid propagation physics model used to produce the results in this section. The system perscription in table \ref {tab:fiducial_observatory_specs} is loaded into Zemax OpticStudio and shown on the left (labeled HST). The phase of the vector vortex coronagraph (VVC) is shown in the middle. The GBD PSF is computed at this plane and propagated through the coronagraph using HCIPy to arrive at the final image at the detector plane.}{35}
\ChangesListline {replaced}{Replaced}{in section 4.2}{35}
\ChangesListline {replaced}{Replaced}{1 $\times $ 1 mm}{35}
\ChangesListline {replaced}{Replaced}{conducted in section 4.3 are}{35}
\ChangesListline {replaced}{Replaced}{1600 $\times $ 1600 pixels across 8 $\times $ 8 mm}{35}
\ChangesListline {replaced}{Replaced}{2}{36}
\ChangesListline {replaced}{Replaced}{which accepts a user-specified wavefront and then outputs the wavefront before the lyot stop. We can define our GBD PSF as an HCIPy wavefront and propagate it through the coronagraph to complete our hybrid propagation model and analyze the image plane residuals.}{37}
\ChangesListline {replaced}{Replaced}{in figures \ref {fig:airy_even} and \ref {fig:airy_fib}}{37}
\ChangesListline {added}{Added}{the}{38}
\ChangesListline {added}{Added}{To further test GBD's capability to model a more realistic observatory PSF, we add obscurations in the entrance pupil that correspond to the secondary mirror and supporting spiders. We also tilt the secondary mirror by 0.05 degrees to aberrate the beam. By doing so, we simultaneously test our algorithm's ability to capture aberrations from optical misalignment. The results of this simulation are shown in Figure \ref {fig:aberrated}}{41}
\ChangesListline {added}{Added}{Simulations of an aberrated PSF with secondary support structure in the entrance pupil of our HST model given in Table \ref {tab:fiducial_observatory_specs}. The GBD PSF (left) and Zemax Huygens PSF (right) have very similar structure, with the dominant difference in structure being the features from the sharp-edge diffraction from the spiders (shown in fractional difference on the right). This simulation helps quantify the degree to which GBD's difficulty in modeling sharp-edge diffraction effects. The RMS difference of the PSF data is 7.5e-6.}{41}
\ChangesListline {added}{Added}{The data in figure \ref {fig:aberrated} was simulated in a comparison between our proposed algorithm and Zemax's Huygens PSF analysis tool. In this simulation we vignette any Gaussian Beam that has any of its differential rays vignetted. Our results show extremely similar structure in the PSF from both the aberation induced by the secondary mirror misalignment and the structure from the HST spiders. The fractional difference reveals that the first couple "rings" of the PSFs are almost identical, indicating that the low-order aberrations were sufficiently simulated by GBD. There is a larger fractional difference in the dimmer structures that result from the sharp edges of the secondary obscuration and spiders, which is a known challenge for GBD simulations. This result can be further improved by careful implementation of alternative beamlet profiles, such as Worku and Gross's truncated beamlets\cite {Worku19}, or higher-order transverse electric field modes (e.g. Hermite, Laguerre-Gaussian). However, the result using fundamental Gaussian modes is encouraging, since the RMS difference of the PSFs is within the same order of magnitude as the results shown in Figures \ref {fig:airy_even} and \ref {fig:airy_fib}. Now that our algorithm's ability to perform PSF simulations has been verified, we can analyze the degree to which it introduces artifacts in high-contrast imaging simulations.}{42}
\ChangesListline {replaced}{Replaced}{1600}{42}
\ChangesListline {replaced}{Replaced}{4.95}{42}
\ChangesListline {added}{Added}{from 3-30 $\lambda / D$}{43}
\ChangesListline {replaced}{Replaced}{HST}{43}
\ChangesListline {replaced}{Replaced}{2}{43}
\ChangesListline {added}{Added}{(e) with 500 beamlets, and (f) with 600 beamlets across the aperture}{43}
\ChangesListline {replaced}{Replaced}{2}{43}
\ChangesListline {replaced}{Replaced}{$\approx 16 \lambda /D$}{43}
\ChangesListline {replaced}{Replaced}{from the Hybrid propagation (b-f) are brighter than the equivalent Fraunhofer simulation, and minimize at the 500 beamlet case. This is particularly apparent near the inner working angle, where we see a signal of $\approx $ $1 \times 10^-8$ for the 200 beamlet case decrease to $\approx 5 \times 10^{-9}$ in the 500 beamlet case. }{43}
\ChangesListline {deleted}{Deleted}{more computational resources or}{43}
\ChangesListline {replaced}{Replaced}{that}{43}
\ChangesListline {replaced}{Replaced}{generally minimizes in average contrast until the 600 beamlet case (Figure \ref {fig:nonparaxial_coronagraph}f) where there is a slight increase.}{44}
\ChangesListline {added}{Added}{which can be improved with greater sampling}{44}
\ChangesListline {added}{Added}{ The increase in average contrast in figure \ref {fig:nonparaxial_coronagraph}f suggests that we have determined the limit that traditional GBD can be used to practically mimic a PSF given this sampling of the focal plane.}{44}
\ChangesListline {added}{Added}{Python's ability to vectorize matrix operations and other Python packages to accelerate the exponential calculation}{44}
\ChangesListline {deleted}{Deleted}{numpy's array broadcasting operations, and numexpr's accelerated exponential calculation}{44}
\ChangesListline {added}{Added}{discussed in detail in Appendix A}{44}
\ChangesListline {added}{Added}{near the inner working angle}{44}
\ChangesListline {added}{Added}{It is also worth noting that this result suggests that with sufficient sampling, GBD can presently be used to simulate the PSFs for systems with less stringent contrast floors.}{45}
\ChangesListline {replaced}{Replaced}{have created a platform for the algorithm's development in an open-source environment and will outline a road map for the most pressing optimizations that can be conducted by future investigations.}{45}
\ChangesListline {added}{Added}{near}{45}
\ChangesListline {deleted}{Deleted}{$10^{-9}$}{45}
\ChangesListline {added}{Added}{at $< 10^{-9}$ with an numerical average contrast of $4\times 10^{-11}$}{45}
\ChangesListline {deleted}{Deleted}{We also outline a path forward for the ongoing development of this technique to make it suitable for simulations of Earth-like exoplanet signals at contrasts of $10^{-10}$.}{45}
\ChangesListline {replaced}{Replaced}{360,000}{46}
\ChangesListline {replaced}{Replaced}{2,560,000}{46}
\ChangesListline {replaced}{Replaced}{100TB}{46}
\ChangesListline {replaced}{Replaced}{24}{46}
\ChangesListline {added}{Added}{Preliminary efforts in accelerated computing are discussed in Appendix A. Through careful optimization of our algorithm we were able to decrease the runtime considerably.}{46}
\ChangesListline {replaced}{Replaced}{is capable of}{46}
\ChangesListline {replaced}{Replaced}{The Beamlet decomposition algorithm}{47}
\ChangesListline {added}{Added}{Preliminary experiments on GPU's have shown a decrease in runtime by a factor of $\approx $16.}{47}
\ChangesListline {added}{Added}{The use of a beamlet decomposition algorithm completely integrates a diffraction model with a ray model of an optical system, resulting in a more physically complete modeling pipeline}{47}
\ChangesListline {added}{Added}{, which may be sensitive to polarization aberrations}{47}
\ChangesListline {replaced}{Replaced}{Using the Cupy python package, adding support for GPU's was made quite simple given its compatibility with the numpy API. Preliminary experiments using our beamlet decomposition algorithm show a $\approx $16$\times $ decrease in computation time across all cases tested. We have added GPU support though Cupy in our poke package and plan to publish a formal study quantifying the degree to which GBD can benefit from accelerated computing in a future report.}{50}
\ChangesListline {added}{Added}{Illustration of the operating principle of GBD in one dimension. The aperture function for traditional imaging systems is shown in (a) as a top-hat function of uniform amplitude. The decomposition of this function into a discrete set of Gaussian beams is shown in (b), which shows nine evenly-spaced Gaussian profiles before their coherent summation, which is shown in (c). The coherent sum (black) of these nine beamlets shows that the beamlets are incapable of perfectly reconstructing the original aperture function (dashed red), specifically the sharp edge and uniform amplitude. More beamlets are needed for a more accurate reconstruction, which is shown in (d) for 199 beamlets. The amplitude ripple has virtually vanished, and the field near the aperture edges is almost entirely recovered.}{53}
\ChangesListline {added}{Added}{Illustration of Poke's use as an interface to open-source ray-based physical optics. Poke only requires an interface between a ray tracing engine (orange, left) to generate and save a Rayfront object, which includes all ray data necessary for the GBD calculation. Currently, Poke supports sequential systems in CODE V and Zemax, but we are working on adding support for open-source packages that have ray tracers, like ray-optics\cite {rayoptics}. The GBD field that Poke computes can then be sent to any open-source diffraction modeling package (yellow, right) to complete the hybrid propagation model.}{54}
\ChangesListline {added}{Added}{Illustration of relevant ray parameters necessary to propagate the ray data to the transversal plane, where we evaluate the Gaussian field that intersects with a detector pixel. A ray that defines a Gaussian beam is placed on the source plane (leftmost vertical dashed line) with some direction ($\mathbf {k}_{ray,S}$) and position ($\mathbf {r}_{ray,S}$) and propagated though the system. At the detector plane (rightmost vertical dashed line), the ray's direction and positions ($\mathbf {k}_{ray,D}$ and $\mathbf {r}_{ray,D}$ respectively) have been transformed by the optical system. To propagate the rays to the transversal plane (tilted dashed line) that intersects the pixel at $\mathbf {r}_{pixel,D}$ where the field evaluation occurs, it must be moved a distance $\Delta _{ray}$ along the ray path in detector space.}{55}
\ChangesListline {added}{Added}{Illustration of the hybrid propagation physics model used to produce the results in this section. The system perscription in table \ref {tab:fiducial_observatory_specs} is loaded into Zemax OpticStudio and shown on the left (labeled HST). The phase of the vector vortex coronagraph (VVC) is shown in the middle. The GBD PSF is computed at this plane and propagated through the coronagraph using HCIPy to arrive at the final image at the detector plane.}{56}
\ChangesListline {added}{Added}{the}{57}
\ChangesListline {added}{Added}{Simulations of an aberrated PSF with secondary support structure in the entrance pupil of our HST model given in Table \ref {tab:fiducial_observatory_specs}. The GBD PSF (left) and Zemax Huygens PSF (right) have very similar structure, with the dominant difference in structure being the features from the sharp-edge diffraction from the spiders (shown in fractional difference on the right). This simulation helps quantify the degree to which GBD's difficulty in modeling sharp-edge diffraction effects. The RMS difference of the PSF data is 7.5e-6.}{58}
\ChangesListline {added}{Added}{from 3-30 $\lambda / D$}{59}
\ChangesListline {replaced}{Replaced}{HST}{59}
\ChangesListline {replaced}{Replaced}{2}{59}
\ChangesListline {added}{Added}{(e) with 500 beamlets, and (f) with 600 beamlets across the aperture}{59}
\ChangesListline {replaced}{Replaced}{2}{59}
\ChangesListline {replaced}{Replaced}{$\approx 16 \lambda /D$}{59}
\ChangesListline {replaced}{Replaced}{from the Hybrid propagation (b-f) are brighter than the equivalent Fraunhofer simulation, and minimize at the 500 beamlet case. This is particularly apparent near the inner working angle, where we see a signal of $\approx $ $1 \times 10^-8$ for the 200 beamlet case decrease to $\approx 5 \times 10^{-9}$ in the 500 beamlet case. }{59}
\ChangesListline {deleted}{Deleted}{more computational resources or}{59}
